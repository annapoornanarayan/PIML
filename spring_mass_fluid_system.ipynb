{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used pandas to read csv file\n",
    "df = pd.read_csv('damped_harmonic_oscillator_data.csv')\n",
    "\n",
    "t = df['t'].to_numpy()\n",
    "x = df['x'].to_numpy()\n",
    "print(df)\n",
    "plt.plot(t,x)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Position')\n",
    "plt.title('Given data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = t.reshape(-1, 1)  # time\n",
    "X = x.reshape(-1, 1)  # position\n",
    "print(T[0],X[0])\n",
    "print(T.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data [40 % testing and 60% training]\n",
    "#20%(test) ---- 60% (train)--- 20% (test)\n",
    "\n",
    "marker_1 = int(0.2 * len(df))\n",
    "marker_2 = int(0.8 * len(df))\n",
    "\n",
    "# TRAINING DATA\n",
    "train_data = df.iloc[marker_1:marker_2]\n",
    "T_train = train_data.iloc[:, :1].to_numpy().reshape(-1, 1)  # time\n",
    "X_train = train_data.iloc[:, 1:].to_numpy().reshape(-1, 1)  # position\n",
    "\n",
    "# TESTING DATA\n",
    "first_half_test = df.iloc[:marker_1]\n",
    "second_half_test = df.iloc[marker_2:]\n",
    "\n",
    "test_data = pd.concat([first_half_test, second_half_test])\n",
    "\n",
    "T_test = test_data.iloc[:, :1].to_numpy().reshape(-1, 1)  # time\n",
    "X_test = test_data.iloc[:, 1:].to_numpy().reshape(-1, 1)  # position\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Shape of T_train:\", T_train.shape)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of T_test:\", T_test.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "T_train_tensor = torch.tensor(T_train, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "T_test_tensor = torch.tensor(T_test, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.seed()\n",
    "\n",
    "class SGDRegression(nn.Module):\n",
    "    def __init__(self, activation_fn):\n",
    "        super(SGDRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 16)  # Input layer [1 input]\n",
    "        self.fc2 = nn.Linear(16, 16)  # Hidden layer 1\n",
    "        self.fc3 = nn.Linear(16, 16)  # Hidden layer 2\n",
    "        self.fc4 = nn.Linear(16, 1)   # Output layer [1 output]\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_fn(self.fc1(x))  \n",
    "        x = self.activation_fn(self.fc2(x)) \n",
    "        x = self.activation_fn(self.fc3(x))  \n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "    'ReLU': F.relu,\n",
    "    'Sigmoid': torch.sigmoid,\n",
    "    'Tanh': torch.tanh,\n",
    "    'LeakyReLU': F.leaky_relu,\n",
    "    'ELU': F.elu,\n",
    "    'SELU': F.selu,\n",
    "    'GELU': F.gelu,\n",
    "    'Softplus': F.softplus,\n",
    "    'Softsign': F.softsign,\n",
    "    'ReLU6': F.relu6,\n",
    "    'Hardtanh': F.hardtanh,\n",
    "    'LogSigmoid': F.logsigmoid\n",
    "}\n",
    "# Dictionary to store losses corresponding to each actvation function\n",
    "all_losses = {name: [] for name in activation_functions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(T_train_tensor, X_train_tensor)\n",
    "data_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for activation_name, activation_fn in activation_functions.items():\n",
    "    model = SGDRegression(activation_fn)\n",
    "    loss_fn = torch.nn.MSELoss() # we want to model mean square loss\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    EPOCHS = 50\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch, (input_data, output_data) in enumerate(data_loader):\n",
    "\n",
    "            X_pred = model(input_data)\n",
    "            loss = loss_fn(X_pred, output_data)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    \n",
    "    all_losses[activation_name] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss curves in subplots\n",
    "num_activations = len(activation_functions)\n",
    "cols = 4  \n",
    "rows = (num_activations + cols - 1) // cols \n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (activation_name, losses) in enumerate(all_losses.items()):\n",
    "    ax = axes[i]\n",
    "    ax.plot(losses)\n",
    "    ax.set_title(activation_name)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_pred = model(T_test_tensor)\n",
    "    X_train_pred = model(T_train_tensor)\n",
    "X_test_pred = X_test_pred.numpy()\n",
    "X_train_pred = X_train_pred.numpy()\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.plot(T_test, X_test, 'g.', label='Test Actual')\n",
    "plt.plot(T_test, X_test_pred,'r.', label='Test Predicted')\n",
    "plt.plot(T_train, X_train, 'y.', label='Train Actual')\n",
    "plt.plot(T_train, X_train_pred,'b.', label='Train Calculated')\n",
    "\n",
    "plt.xlabel('Time (t)')\n",
    "plt.ylabel('Position (x)')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
