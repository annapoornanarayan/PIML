{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81492437-56f9-49d3-8f14-3159ca6c4f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e338a04-75e9-4d05-9701-1c4554177a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape  (700000, 201)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "df = pd.read_csv('quantum_harmonic_oscillator_timed_data.csv')\n",
    "print(\"Dataset shape \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7aee4fb-cd6f-4b94-b079-c10a958d1277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_data: (420000, 201)\n",
      "Shape of test_data: (280000, 201)\n",
      "\n",
      "Shape of train time (420000,)\n",
      "Shape of test time (280000,)\n",
      "\n",
      "Shape of feat_train: (420000, 100)\n",
      "Shape of targ_train: (420000, 100)\n",
      "Shape of feat_test: (280000, 100)\n",
      "Shape of targ_test: (280000, 100)\n"
     ]
    }
   ],
   "source": [
    "marker_1 = int(0.2 * len(df))\n",
    "marker_2 = int(0.8 * len(df))\n",
    "\n",
    "# Split into training and testing data\n",
    "train_data = df.iloc[marker_1:marker_2]\n",
    "test_data = pd.concat([df.iloc[:marker_1], df.iloc[marker_2:]])\n",
    "\n",
    "# Verifying shapes\n",
    "print(\"Shape of train_data:\", train_data.shape)\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "print()\n",
    "\n",
    "# TIME DATA\n",
    "T = df.iloc[:, 0]\n",
    "time_train = T.iloc[marker_1:marker_2]\n",
    "time_test = pd.concat([T.iloc[:marker_1], T.iloc[marker_2:]])\n",
    "print(\"Shape of train time\", time_train.shape)\n",
    "print(\"Shape of test time\", time_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# TRAINING DATA\n",
    "feat_train = train_data.iloc[:, 1:101].values  # 1 to 101 columns are features\n",
    "targ_train = train_data.iloc[:, 101:].values  # the next 100 columns are targets\n",
    "\n",
    "# TESTING DATA\n",
    "feat_test = test_data.iloc[:, 1:101].values\n",
    "targ_test = test_data.iloc[:, 101:].values\n",
    "\n",
    "# Verifying shapes\n",
    "print(\"Shape of feat_train:\", feat_train.shape)\n",
    "print(\"Shape of targ_train:\", targ_train.shape)\n",
    "print(\"Shape of feat_test:\", feat_test.shape)\n",
    "print(\"Shape of targ_test:\", targ_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a9f6de-0c55-4cd0-a4d0-940e44e3c289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420000, 1)\n",
      "(280000, 1)\n"
     ]
    }
   ],
   "source": [
    "time_train = time_train.values.reshape(-1, 1)\n",
    "time_test = time_test.values.reshape(-1,1)\n",
    "print(time_train.shape)\n",
    "print(time_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3b14b-fef6-44be-996a-0c5fa3daef1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert strings to complex numbers\n",
    "time_train_tensor = np.vectorize(complex)(time_train)\n",
    "time_test_tensor = np.vectorize(complex)(time_test)\n",
    "F_train = np.vectorize(complex)(feat_train)\n",
    "T_train = np.vectorize(complex)(targ_train)\n",
    "F_test = np.vectorize(complex)(feat_test)\n",
    "T_test= np.vectorize(complex)(targ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc0d54e-469a-4dd6-98d8-bba86d5860da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([280000, 1]) torch.Size([420000, 1])\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "time_train_tensor = torch.tensor(time_train_tensor, dtype = torch.complex64)\n",
    "time_test_tensor = torch.tensor(time_test_tensor, dtype = torch.complex64)\n",
    "F_train_tensor = torch.tensor(F_train, dtype = torch.complex64)\n",
    "T_train_tensor = torch.tensor(T_train, dtype = torch.complex64)\n",
    "F_test_tensor = torch.tensor(F_test, dtype = torch.complex64)\n",
    "T_test_tensor = torch.tensor(T_test, dtype = torch.complex64)\n",
    "print(time_test_tensor.shape, time_train_tensor.shape)\n",
    "print(time_test_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d2466d9-ea94-4e47-a080-adaa90697c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeaveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeaveNet, self).__init__()\n",
    "        self.pos_1 = nn.Linear(100, 200, dtype=torch.complex64)\n",
    "        self.pos_2 = nn.Linear(200, 100, dtype=torch.complex64)\n",
    "\n",
    "        self.time_1 = nn.Linear(1, 20, dtype=torch.complex64)\n",
    "        self.time_2 = nn.Linear(20, 100, dtype=torch.complex64)  \n",
    "\n",
    "        self.mesh_1 = nn.Linear(200, 220, dtype=torch.complex64)  \n",
    "        self.mesh_2 = nn.Linear(220, 200, dtype=torch.complex64)\n",
    "        \n",
    "        self.pos_3 = nn.Linear(100, 200, dtype=torch.complex64)\n",
    "        self.pos_4 = nn.Linear(200, 100, dtype=torch.complex64)\n",
    "        \n",
    "        self.time_3 = nn.Linear(1, 20, dtype=torch.complex64)\n",
    "        self.time_4 = nn.Linear(20, 100, dtype=torch.complex64)\n",
    "        \n",
    "        self.mesh_3 = nn.Linear(200, 220, dtype=torch.complex64)\n",
    "        self.mesh_4 = nn.Linear(220, 100, dtype=torch.complex64)  \n",
    "\n",
    "    def forward(self, pos, time):\n",
    "        ### Chunk 1 ###\n",
    "        pos = torch.tanh(self.pos_1(pos))\n",
    "        time = torch.tanh(self.time_1(time))\n",
    "        time = torch.tanh(self.time_2(time))  \n",
    "        combined = torch.cat((pos, time), dim=-1)\n",
    "        combined = torch.tanh(self.mesh_1(combined))\n",
    "\n",
    "        ### Chunk 2 ###\n",
    "        combined = torch.tanh(self.mesh_2(combined))\n",
    "        pos, time = combined[:, :100], combined[:, 100:]\n",
    "\n",
    "        pos = torch.tanh(self.pos_3(pos))\n",
    "        time = torch.tanh(self.time_3(time))\n",
    "        time = torch.tanh(self.time_4(time)) \n",
    "        combined = torch.cat((pos, time), dim=-1)\n",
    "        combined = torch.tanh(self.mesh_3(combined))\n",
    "        \n",
    "        combined = torch.tanh(self.mesh_4(combined))\n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32590415-a7b5-4428-9425-25ca41595e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, data_preds, data_targs):\n",
    "        # data loss\n",
    "        diff = data_preds - data_targs\n",
    "        diff_dag = torch.conj(diff)\n",
    "        loss_data = torch.mean(diff*diff_dag)\n",
    "        return loss_data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e305f8a1-abc7-4ac1-b770-87c2a222da29",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (20x300 and 200x220)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (input_data, time_col, output_data) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m---> 18\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, output_data)\n\u001b[1;32m     20\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/reu/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/reu/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 28\u001b[0m, in \u001b[0;36mWeaveNet.forward\u001b[0;34m(self, pos, time)\u001b[0m\n\u001b[1;32m     26\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_2(time))  \n\u001b[1;32m     27\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((pos, time), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmesh_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m### Chunk 2 ###\u001b[39;00m\n\u001b[1;32m     31\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmesh_2(combined))\n",
      "File \u001b[0;32m~/.conda/envs/reu/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/reu/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/reu/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20x300 and 200x220)"
     ]
    }
   ],
   "source": [
    "#from tensorboardX import SummaryWriter\n",
    "BATCH_SIZE = 20 #change this\n",
    "EPOCHS = 7 #1000s of epochs\n",
    "LR = 0.01\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(F_train_tensor, time_train_tensor, T_train_tensor)\n",
    "data_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "size = len(data_loader.dataset)\n",
    "model = WeaveNet()\n",
    "loss_fn = CustomLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "losses = []\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    for batch, (input_data, time_col, output_data) in enumerate(data_loader):\n",
    "\n",
    "        pred = model(input_data, time_col)\n",
    "        loss = loss_fn(pred, output_data)\n",
    "        losses.append(loss.item())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "print(\"Done\")\n",
    "#i and r instead of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df656990-51b0-468d-9b22-5ce751ff7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = list(range(1, len(losses) + 1))\n",
    "plt.plot(EPOCHS, losses)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1499c60-2e5f-4515-9c7a-59893ca1bd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly select a subset of the test data\n",
    "#Evaluating\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(F_test_tensor, time_test_tensor)\n",
    "test_pred = test_pred.numpy()\n",
    "\n",
    "num_samples = 5  # Number of samples to plot\n",
    "indices = np.random.choice(F_test_tensor.shape[0], num_samples)\n",
    "print(indices)\n",
    "\n",
    "# Get the true and predicted values for these indices\n",
    "true_values = T_test_tensor[indices].numpy()\n",
    "predicted_values = test_pred[indices]\n",
    "\n",
    "# Plotting the results\n",
    "fig, axs = plt.subplots(num_samples, 1, figsize=(10, 5 * num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axs[i].plot(range(100), true_values[i], color='blue', label='True Values')\n",
    "    axs[i].plot(range(100), predicted_values[i], color='red', label='Predicted Values')\n",
    "    axs[i].plot(range(100), true_values[i].imag, color='green', label='True Values')\n",
    "    axs[i].plot(range(100), predicted_values[i].imag, color='black', label='Predicted Values')\n",
    "    axs[i].set_title(f'Sample {i+1}')\n",
    "    axs[i].set_xlabel('Feature Index')\n",
    "    axs[i].set_ylabel('Value')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-reu]",
   "language": "python",
   "name": "conda-env-.conda-reu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
